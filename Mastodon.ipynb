{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7711ae6e-a51f-4624-a07d-54e823a6529b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/daniellelott/anaconda3/lib/python3.11/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/daniellelott/anaconda3/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in /Users/daniellelott/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/daniellelott/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/daniellelott/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/daniellelott/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (4.66.1)\n",
      "\u001b[33mDEPRECATION: nb-black 1.0.7 has a non-standard dependency specifier black>='19.3'; python_version >= \"3.6\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of nb-black or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf4daa30-91b5-43ed-88fe-bf044a568364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from textblob import TextBlob  # Import TextBlob for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d43db625-d209-4899-8048-cd3a25eabd11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Content Shift Analysis\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Extract hashtags from toots (using 'tags' key)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m hashtags \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [tag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m x] \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m [])\u001b[38;5;241m.\u001b[39mexplode()\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Calculate the frequency of each hashtag\u001b[39;00m\n\u001b[1;32m     47\u001b[0m popular_hashtags \u001b[38;5;241m=\u001b[39m hashtags\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/range.py:418\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tags'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "hashtag = 'twitter'\n",
    "URL = f'https://mastodon.social/api/v1/timelines/tag/{hashtag}'\n",
    "params = {\n",
    "    'limit': 70\n",
    "}\n",
    "\n",
    "start_date = pd.Timestamp('2022-01-01', tz='utc')\n",
    "end_date = pd.Timestamp('2023-08-31', tz='utc')\n",
    "\n",
    "results = []\n",
    "\n",
    "while True:\n",
    "    r = requests.get(URL, params=params)\n",
    "    toots = json.loads(r.text)\n",
    "\n",
    "    if len(toots) == 0:\n",
    "        break\n",
    "    \n",
    "    for t in toots:\n",
    "        timestamp = pd.Timestamp(t['created_at'], tz='utc')\n",
    "        \n",
    "        if start_date <= timestamp <= end_date:\n",
    "            results.append(t)\n",
    "            \n",
    "        elif timestamp < start_date:\n",
    "            is_end = True\n",
    "            break\n",
    "    \n",
    "    if is_end:\n",
    "        break\n",
    "    \n",
    "    max_id = toots[-1]['id']\n",
    "    params['max_id'] = max_id\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Content Shift Analysis\n",
    "# Extract hashtags from toots (using 'tags' key)\n",
    "hashtags = df['tags'].apply(lambda x: [tag['name'] for tag in x] if x else []).explode().dropna()\n",
    "\n",
    "# Calculate the frequency of each hashtag\n",
    "popular_hashtags = hashtags.value_counts()\n",
    "\n",
    "print(\"Popular Hashtags:\")\n",
    "print(popular_hashtags.head(10))\n",
    "\n",
    "# Sentiment Analysis\n",
    "df['sentiment'] = df['content'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "average_sentiment = df['sentiment'].mean()\n",
    "\n",
    "print(f\"Average Sentiment: {average_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbc953c5-e257-4250-aefb-5633c0e9ea39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b87518a5-da10-4bca-8530-2e8a9b9feb03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['id', 'created_at', 'in_reply_to_id', 'in_reply_to_account_id',\n",
      "       'sensitive', 'spoiler_text', 'visibility', 'language', 'uri', 'url',\n",
      "       'replies_count', 'reblogs_count', 'favourites_count', 'edited_at',\n",
      "       'content', 'reblog', 'media_attachments', 'mentions', 'tags', 'emojis',\n",
      "       'card', 'poll', 'account.id', 'account.username', 'account.acct',\n",
      "       'account.display_name', 'account.locked', 'account.bot',\n",
      "       'account.discoverable', 'account.group', 'account.created_at',\n",
      "       'account.note', 'account.url', 'account.uri', 'account.avatar',\n",
      "       'account.avatar_static', 'account.header', 'account.header_static',\n",
      "       'account.followers_count', 'account.following_count',\n",
      "       'account.statuses_count', 'account.last_status_at', 'account.emojis',\n",
      "       'account.fields', 'card.url', 'card.title', 'card.description',\n",
      "       'card.language', 'card.type', 'card.author_name', 'card.author_url',\n",
      "       'card.provider_name', 'card.provider_url', 'card.html', 'card.width',\n",
      "       'card.height', 'card.image', 'card.image_description', 'card.embed_url',\n",
      "       'card.blurhash', 'card.published_at', 'application.name',\n",
      "       'application.website', 'account.noindex', 'account.roles'],\n",
      "      dtype='object')\n",
      "Number of Rows: 9\n",
      "Sample Row: id                              111503760622198963\n",
      "created_at                2023-12-01T06:32:39.000Z\n",
      "in_reply_to_id                                None\n",
      "in_reply_to_account_id                        None\n",
      "sensitive                                    False\n",
      "                                    ...           \n",
      "card.published_at                              NaN\n",
      "application.name                               NaN\n",
      "application.website                            NaN\n",
      "account.noindex                                NaN\n",
      "account.roles                                  NaN\n",
      "Name: 0, Length: 65, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# TRENDING TOPICS HERE, PLEASE\n",
    "hashtags = ['ONS'] #change to the chosen trending topics\n",
    "\n",
    "results = []\n",
    "is_end = False\n",
    "limit = 70\n",
    "\n",
    "for hashtag in hashtags:\n",
    "    URL = f'https://mastodon.social/api/v1/timelines/tag/{hashtag}'\n",
    "    params = {\n",
    "        'limit': limit\n",
    "    }\n",
    "\n",
    "start_date = pd.Timestamp('2023-11-05', tz='utc')\n",
    "end_date = pd.Timestamp('2023-12-05', tz='utc')\n",
    "\n",
    "while not is_end:\n",
    "    try:\n",
    "        r = requests.get(URL, params=params)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        api_response = json.loads(r.text)\n",
    "\n",
    "        if len(api_response) == 0:\n",
    "            break\n",
    "\n",
    "        for t in api_response:\n",
    "            timestamp = pd.Timestamp(t['created_at'], tz='utc')\n",
    "\n",
    "            if start_date <= timestamp <= end_date:\n",
    "                results.append(t)\n",
    "\n",
    "            elif timestamp < start_date:\n",
    "                is_end = True\n",
    "                break\n",
    "\n",
    "        if is_end:\n",
    "            break\n",
    "\n",
    "        max_id = api_response[-1]['id']\n",
    "        params['max_id'] = max_id\n",
    "\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print('HTTP Error:', errh)\n",
    "        break\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print('Error:', err)\n",
    "        break\n",
    "\n",
    "df = pd.json_normalize(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Number of Rows:\", len(df))\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"Sample Row:\", df.iloc[0])\n",
    "else:\n",
    "    print(\"DataFrame is empty.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c27ce05-7d76-4986-bc70-cd41b4b9829f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 60)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "754aa926-e0a2-40a2-8a8d-a893444ac9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['id', 'created_at', 'in_reply_to_id', 'in_reply_to_account_id',\n",
      "       'sensitive', 'spoiler_text', 'visibility', 'language', 'uri', 'url',\n",
      "       'replies_count', 'reblogs_count', 'favourites_count', 'edited_at',\n",
      "       'content', 'reblog', 'media_attachments', 'mentions', 'tags', 'emojis',\n",
      "       'poll', 'account.id', 'account.username', 'account.acct',\n",
      "       'account.display_name', 'account.locked', 'account.bot',\n",
      "       'account.discoverable', 'account.group', 'account.created_at',\n",
      "       'account.note', 'account.url', 'account.uri', 'account.avatar',\n",
      "       'account.avatar_static', 'account.header', 'account.header_static',\n",
      "       'account.followers_count', 'account.following_count',\n",
      "       'account.statuses_count', 'account.last_status_at', 'account.emojis',\n",
      "       'account.fields', 'card.url', 'card.title', 'card.description',\n",
      "       'card.language', 'card.type', 'card.author_name', 'card.author_url',\n",
      "       'card.provider_name', 'card.provider_url', 'card.html', 'card.width',\n",
      "       'card.height', 'card.image', 'card.image_description', 'card.embed_url',\n",
      "       'card.blurhash', 'card.published_at', 'card', 'application.name',\n",
      "       'application.website', 'account.noindex', 'account.roles', 'poll.id',\n",
      "       'poll.expires_at', 'poll.expired', 'poll.multiple', 'poll.votes_count',\n",
      "       'poll.voters_count', 'poll.options', 'poll.emojis', 'account.moved.id',\n",
      "       'account.moved.username', 'account.moved.acct',\n",
      "       'account.moved.display_name', 'account.moved.locked',\n",
      "       'account.moved.bot', 'account.moved.discoverable',\n",
      "       'account.moved.group', 'account.moved.created_at', 'account.moved.note',\n",
      "       'account.moved.url', 'account.moved.uri', 'account.moved.avatar',\n",
      "       'account.moved.avatar_static', 'account.moved.header',\n",
      "       'account.moved.header_static', 'account.moved.followers_count',\n",
      "       'account.moved.following_count', 'account.moved.statuses_count',\n",
      "       'account.moved.last_status_at', 'account.moved.noindex',\n",
      "       'account.moved.emojis', 'account.moved.roles', 'account.moved.fields',\n",
      "       'application'],\n",
      "      dtype='object')\n",
      "Number of Rows: 4620\n",
      "Sample Row: id                              111524782024215566\n",
      "created_at                2023-12-04T23:38:42.788Z\n",
      "in_reply_to_id                  111524745150115711\n",
      "in_reply_to_account_id                     1234906\n",
      "sensitive                                    False\n",
      "                                    ...           \n",
      "account.moved.noindex                          NaN\n",
      "account.moved.emojis                           NaN\n",
      "account.moved.roles                            NaN\n",
      "account.moved.fields                           NaN\n",
      "application                                    NaN\n",
      "Name: 0, Length: 98, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# TRENDING TOPICS HERE, PLEASE\n",
    "hashtags = ['twitter'] #change to the chosen trending topics\n",
    "\n",
    "results = []\n",
    "is_end = False\n",
    "limit = 70\n",
    "\n",
    "for hashtag in hashtags:\n",
    "    URL = f'https://mastodon.social/api/v1/timelines/tag/{hashtag}'\n",
    "    params = {\n",
    "        'limit': limit\n",
    "    }\n",
    "\n",
    "start_date = pd.Timestamp('2023-11-05', tz='utc')\n",
    "end_date = pd.Timestamp('2023-12-05', tz='utc')\n",
    "\n",
    "while not is_end:\n",
    "    try:\n",
    "        r = requests.get(URL, params=params)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        api_response = json.loads(r.text)\n",
    "\n",
    "        if len(api_response) == 0:\n",
    "            break\n",
    "\n",
    "        for t in api_response:\n",
    "            timestamp = pd.Timestamp(t['created_at'], tz='utc')\n",
    "\n",
    "            if start_date <= timestamp <= end_date:\n",
    "                results.append(t)\n",
    "\n",
    "            elif timestamp < start_date:\n",
    "                is_end = True\n",
    "                break\n",
    "\n",
    "        if is_end:\n",
    "            break\n",
    "\n",
    "        max_id = api_response[-1]['id']\n",
    "        params['max_id'] = max_id\n",
    "\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print('HTTP Error:', errh)\n",
    "        break\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print('Error:', err)\n",
    "        break\n",
    "\n",
    "df = pd.json_normalize(results)\n",
    "\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Number of Rows:\", len(df))\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"Sample Row:\", df.iloc[0])\n",
    "else:\n",
    "    print(\"DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ea3d501-0572-422a-b815-318b4eb3512b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>in_reply_to_id</th>\n",
       "      <th>in_reply_to_account_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>language</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>reblogs_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>content</th>\n",
       "      <th>...</th>\n",
       "      <th>mentions</th>\n",
       "      <th>account.id</th>\n",
       "      <th>account.username</th>\n",
       "      <th>account.display_name</th>\n",
       "      <th>account.bot</th>\n",
       "      <th>account.created_at</th>\n",
       "      <th>account.followers_count</th>\n",
       "      <th>account.following_count</th>\n",
       "      <th>account.statuses_count</th>\n",
       "      <th>account.last_status_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111524782024215566</td>\n",
       "      <td>2023-12-04T23:38:42.788Z</td>\n",
       "      <td>1.115247e+17</td>\n",
       "      <td>1234906.0</td>\n",
       "      <td>[{'name': '4k', 'url': 'https://mastodon.socia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;Yeah so the &lt;a class=\"hashtag\" href=\"https:...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': '1234906', 'username': 'realcaseyrolli...</td>\n",
       "      <td>1234906</td>\n",
       "      <td>realcaseyrollins</td>\n",
       "      <td>realcaseyrollins ‚úùÔ∏è</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-01T00:00:00.000Z</td>\n",
       "      <td>510</td>\n",
       "      <td>246</td>\n",
       "      <td>28701</td>\n",
       "      <td>2023-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111524748385780199</td>\n",
       "      <td>2023-12-04T23:30:06.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'tweets', 'url': 'https://mastodon.s...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://www.usluck.com/131965/im-s...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>110748756915542912</td>\n",
       "      <td>usluck</td>\n",
       "      <td>USLUCK</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-07-20T00:00:00.000Z</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>45195</td>\n",
       "      <td>2023-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111524740330155806</td>\n",
       "      <td>2023-12-04T23:28:04.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'tweets', 'url': 'https://mastodon.s...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://www.usluck.com/131963/that...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>110748756915542912</td>\n",
       "      <td>usluck</td>\n",
       "      <td>USLUCK</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-07-20T00:00:00.000Z</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>45195</td>\n",
       "      <td>2023-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111524630427384628</td>\n",
       "      <td>2023-12-04T23:00:10.994Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'twitter', 'url': 'https://mastodon....</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;help The BoneBat Show bring the &amp;quot;Comed...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>109360959456805523</td>\n",
       "      <td>filmfreakmafia</td>\n",
       "      <td>Filmfreak Mafia</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-11-17T00:00:00.000Z</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>4300</td>\n",
       "      <td>2023-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111524567482138018</td>\n",
       "      <td>2023-12-04T22:44:06.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'tweets', 'url': 'https://mastodon.s...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://www.usluck.com/131935/this...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>110748756915542912</td>\n",
       "      <td>usluck</td>\n",
       "      <td>USLUCK</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-07-20T00:00:00.000Z</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>45195</td>\n",
       "      <td>2023-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111524559479003288</td>\n",
       "      <td>2023-12-04T22:42:04.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'tweets', 'url': 'https://mastodon.s...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://www.usluck.com/131933/whil...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>110748756915542912</td>\n",
       "      <td>usluck</td>\n",
       "      <td>USLUCK</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-07-20T00:00:00.000Z</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>45195</td>\n",
       "      <td>2023-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111524539288077029</td>\n",
       "      <td>2023-12-04T22:36:48.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'twitter', 'url': 'https://mastodon....</td>\n",
       "      <td>ja</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://mstdn.jp/tags/%E3%82%A2%E3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>110205620691279091</td>\n",
       "      <td>kimoota09</td>\n",
       "      <td>Ëçí„Å∂„Çã„Ç≠„É¢„É≤„ÇøÂêõÔº†ÂÄâÂ∫´</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-03-03T00:00:00.000Z</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>424</td>\n",
       "      <td>2023-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>111524516401674594</td>\n",
       "      <td>2023-12-04T22:31:10.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'twitter', 'url': 'https://mastodon....</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;I‚Äôve been missing &lt;a href=\"https://mas.to/t...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>111320687918100468</td>\n",
       "      <td>diurnalli</td>\n",
       "      <td>diurnalli</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-10-29T00:00:00.000Z</td>\n",
       "      <td>113</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111524504445478872</td>\n",
       "      <td>2023-12-04T22:28:05.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'alexsingleton', 'url': 'https://mas...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Twitter still can't believe Alex Singleton'...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>109757680205656117</td>\n",
       "      <td>DenverBroncosNews</td>\n",
       "      <td>Denver Broncos News</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-01-25T00:00:00.000Z</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3456</td>\n",
       "      <td>2023-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>111524491502715965</td>\n",
       "      <td>2023-12-04T22:24:49.795Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'name': 'federacion', 'url': 'https://mastod...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://hispagatos.space/@argument...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': '106744036540832226', 'username': 'arg...</td>\n",
       "      <td>111437496845736853</td>\n",
       "      <td>flan</td>\n",
       "      <td>Custard! üçÆ</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-11-19T00:00:00.000Z</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>163</td>\n",
       "      <td>2023-12-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                created_at  in_reply_to_id  \\\n",
       "0  111524782024215566  2023-12-04T23:38:42.788Z    1.115247e+17   \n",
       "1  111524748385780199  2023-12-04T23:30:06.000Z             NaN   \n",
       "2  111524740330155806  2023-12-04T23:28:04.000Z             NaN   \n",
       "3  111524630427384628  2023-12-04T23:00:10.994Z             NaN   \n",
       "4  111524567482138018  2023-12-04T22:44:06.000Z             NaN   \n",
       "5  111524559479003288  2023-12-04T22:42:04.000Z             NaN   \n",
       "6  111524539288077029  2023-12-04T22:36:48.000Z             NaN   \n",
       "7  111524516401674594  2023-12-04T22:31:10.000Z             NaN   \n",
       "8  111524504445478872  2023-12-04T22:28:05.000Z             NaN   \n",
       "9  111524491502715965  2023-12-04T22:24:49.795Z             NaN   \n",
       "\n",
       "   in_reply_to_account_id                                               tags  \\\n",
       "0               1234906.0  [{'name': '4k', 'url': 'https://mastodon.socia...   \n",
       "1                     NaN  [{'name': 'tweets', 'url': 'https://mastodon.s...   \n",
       "2                     NaN  [{'name': 'tweets', 'url': 'https://mastodon.s...   \n",
       "3                     NaN  [{'name': 'twitter', 'url': 'https://mastodon....   \n",
       "4                     NaN  [{'name': 'tweets', 'url': 'https://mastodon.s...   \n",
       "5                     NaN  [{'name': 'tweets', 'url': 'https://mastodon.s...   \n",
       "6                     NaN  [{'name': 'twitter', 'url': 'https://mastodon....   \n",
       "7                     NaN  [{'name': 'twitter', 'url': 'https://mastodon....   \n",
       "8                     NaN  [{'name': 'alexsingleton', 'url': 'https://mas...   \n",
       "9                     NaN  [{'name': 'federacion', 'url': 'https://mastod...   \n",
       "\n",
       "  language  replies_count  reblogs_count  favourites_count  \\\n",
       "0      NaN              1              0                 1   \n",
       "1       en              0              0                 0   \n",
       "2       en              0              0                 0   \n",
       "3       en              0              1                 0   \n",
       "4       en              0              0                 0   \n",
       "5       en              0              0                 0   \n",
       "6       ja              0              0                 0   \n",
       "7       en              0              2                 1   \n",
       "8       en              0              0                 0   \n",
       "9      NaN              1              0                 0   \n",
       "\n",
       "                                             content  ...  \\\n",
       "0  <p>Yeah so the <a class=\"hashtag\" href=\"https:...  ...   \n",
       "1  <p><a href=\"https://www.usluck.com/131965/im-s...  ...   \n",
       "2  <p><a href=\"https://www.usluck.com/131963/that...  ...   \n",
       "3  <p>help The BoneBat Show bring the &quot;Comed...  ...   \n",
       "4  <p><a href=\"https://www.usluck.com/131935/this...  ...   \n",
       "5  <p><a href=\"https://www.usluck.com/131933/whil...  ...   \n",
       "6  <p><a href=\"https://mstdn.jp/tags/%E3%82%A2%E3...  ...   \n",
       "7  <p>I‚Äôve been missing <a href=\"https://mas.to/t...  ...   \n",
       "8  <p>Twitter still can't believe Alex Singleton'...  ...   \n",
       "9  <p><a href=\"https://hispagatos.space/@argument...  ...   \n",
       "\n",
       "                                            mentions          account.id  \\\n",
       "0  [{'id': '1234906', 'username': 'realcaseyrolli...             1234906   \n",
       "1                                                 []  110748756915542912   \n",
       "2                                                 []  110748756915542912   \n",
       "3                                                 []  109360959456805523   \n",
       "4                                                 []  110748756915542912   \n",
       "5                                                 []  110748756915542912   \n",
       "6                                                 []  110205620691279091   \n",
       "7                                                 []  111320687918100468   \n",
       "8                                                 []  109757680205656117   \n",
       "9  [{'id': '106744036540832226', 'username': 'arg...  111437496845736853   \n",
       "\n",
       "    account.username account.display_name account.bot  \\\n",
       "0   realcaseyrollins  realcaseyrollins ‚úùÔ∏è       False   \n",
       "1             usluck               USLUCK       False   \n",
       "2             usluck               USLUCK       False   \n",
       "3     filmfreakmafia      Filmfreak Mafia       False   \n",
       "4             usluck               USLUCK       False   \n",
       "5             usluck               USLUCK       False   \n",
       "6          kimoota09          Ëçí„Å∂„Çã„Ç≠„É¢„É≤„ÇøÂêõÔº†ÂÄâÂ∫´       False   \n",
       "7          diurnalli            diurnalli       False   \n",
       "8  DenverBroncosNews  Denver Broncos News        True   \n",
       "9               flan           Custard! üçÆ       False   \n",
       "\n",
       "         account.created_at account.followers_count  account.following_count  \\\n",
       "0  2020-07-01T00:00:00.000Z                     510                      246   \n",
       "1  2023-07-20T00:00:00.000Z                     227                        0   \n",
       "2  2023-07-20T00:00:00.000Z                     227                        0   \n",
       "3  2022-11-17T00:00:00.000Z                      41                       19   \n",
       "4  2023-07-20T00:00:00.000Z                     227                        0   \n",
       "5  2023-07-20T00:00:00.000Z                     227                        0   \n",
       "6  2023-03-03T00:00:00.000Z                      72                        1   \n",
       "7  2023-10-29T00:00:00.000Z                     113                       17   \n",
       "8  2023-01-25T00:00:00.000Z                      38                        0   \n",
       "9  2023-11-19T00:00:00.000Z                      45                       48   \n",
       "\n",
       "   account.statuses_count  account.last_status_at  \n",
       "0                   28701              2023-12-06  \n",
       "1                   45195              2023-12-06  \n",
       "2                   45195              2023-12-06  \n",
       "3                    4300              2023-12-06  \n",
       "4                   45195              2023-12-06  \n",
       "5                   45195              2023-12-06  \n",
       "6                     424              2023-12-05  \n",
       "7                      18              2023-12-04  \n",
       "8                    3456              2023-12-06  \n",
       "9                     163              2023-12-06  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "twitter = pd.read_csv('twitter.csv')\n",
    "\n",
    "column_list=['id', 'created_at', 'in_reply_to_id', 'in_reply_to_account_id','tags','language', 'replies_count', 'reblogs_count', 'favourites_count',\n",
    " 'content','media_attachments','mentions','account.id', 'account.username','account.display_name', 'account.bot','account.created_at', \n",
    "'account.followers_count', 'account.following_count', 'account.statuses_count', 'account.last_status_at']\n",
    "\n",
    "twitter_final = twitter[column_list]\n",
    "\n",
    "twitter_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63fbb949-7dc7-4f82-be0b-e3b9e815e80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                content  sentiment_score  \\\n",
      "0     @takeyrtime Por cierto https://www.moddb.com/m...         0.146667   \n",
      "1     #Argentina üá¶üá∑ ¬∑ En campa√±a: NO #BRICS  ni \"neg...         0.000000   \n",
      "2     3. #ArgentinaEn pocos d√≠as la web no va a exis...         0.000000   \n",
      "3     2. #ArgentinaA TODO EL MUNDO üîä descarguen de m...         0.000000   \n",
      "4     Con Nestor se llego a reestructurar la deuda h...         0.000000   \n",
      "...                                                 ...              ...   \n",
      "2882  @sarahc whats wild is not only are hate and fa...        -0.275000   \n",
      "2883  Second impression of #bluesky: People are just...         0.081548   \n",
      "2884  Das Prinzip der #K√ºnstlicheVerknappung, mit de...         0.000000   \n",
      "2885  @erik Wie immer: wegen der #Reichweite. Desweg...         0.000000   \n",
      "2886  Vielen Dank f√ºr den Bericht. Teil des Antrages...         0.000000   \n",
      "\n",
      "     sentiment  \n",
      "0     Positive  \n",
      "1      Neutral  \n",
      "2      Neutral  \n",
      "3      Neutral  \n",
      "4      Neutral  \n",
      "...        ...  \n",
      "2882  Negative  \n",
      "2883  Positive  \n",
      "2884   Neutral  \n",
      "2885   Neutral  \n",
      "2886   Neutral  \n",
      "\n",
      "[2887 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "mastodon_final_v2 = pd.read_csv('mastodon_final_v2.csv')\n",
    "\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Apply the sentiment analysis function to the 'content' column\n",
    "mastodon_final_v2['sentiment_score'] = mastodon_final_v2['content'].apply(get_sentiment)\n",
    "\n",
    "def classify_sentiment(score):\n",
    "    if score > 0:\n",
    "        return 'Positive'\n",
    "    elif score < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "mastodon_final_v2['sentiment'] = mastodon_final_v2['sentiment_score'].apply(classify_sentiment)\n",
    "\n",
    "print(mastodon_final_v2[['content', 'sentiment_score', 'sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b0870465-6405-4cd4-b97c-66bf9db7dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b_/kp_80m4j1c31g3yky48_ftdc0000gn/T/ipykernel_49870/1130213172.py:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(str(text), 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 content\n",
      "3      @takeyrtime Por cierto https://www.moddb.com/m...\n",
      "18     #Argentina üá¶üá∑ ¬∑ En campa√±a: NO #BRICS  ni \"neg...\n",
      "21     3. #ArgentinaEn pocos d√≠as la web no va a exis...\n",
      "22     2. #ArgentinaA TODO EL MUNDO üîä descarguen de m...\n",
      "68     Con Nestor se llego a reestructurar la deuda h...\n",
      "...                                                  ...\n",
      "36377  @sarahc whats wild is not only are hate and fa...\n",
      "36394  Second impression of #bluesky: People are just...\n",
      "36395  Das Prinzip der #K√ºnstlicheVerknappung, mit de...\n",
      "36405  @erik Wie immer: wegen der #Reichweite. Desweg...\n",
      "36415  Vielen Dank f√ºr den Bericht. Teil des Antrages...\n",
      "\n",
      "[2887 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "mastodon_final = pd.read_csv('Mastodon_Final.csv')\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    if pd.isna(text) or isinstance(text, bool):\n",
    "        return text\n",
    "    \n",
    "    soup = BeautifulSoup(str(text), 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "for column in mastodon_final.columns:\n",
    "    if mastodon_final[column].dtype == 'O':\n",
    "        mastodon_final[column] = mastodon_final[column].apply(remove_html_tags)\n",
    "\n",
    "# Drop rows with NaN values after processing\n",
    "mastodon_final = mastodon_final.dropna()\n",
    "\n",
    "\n",
    "mastodon_final.to_csv('mastodon_final_v2.csv', index=False)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(mastodon_final[['content']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16ba47eb-8b77-4540-a3f0-c263eb985ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/daniellelott/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/daniellelott/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.4)\n",
      "\u001b[33mDEPRECATION: nb-black 1.0.7 has a non-standard dependency specifier black>='19.3'; python_version >= \"3.6\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of nb-black or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96a839-323b-4ba3-9ede-fb5f247b2ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
